import numpy as np
import logging
from io import BytesIO
from pydub import AudioSegment
import torch
from transformers import AutoProcessor, MusicgenForConditionalGeneration
from functools import lru_cache
import hashlib
import os

logger = logging.getLogger(__name__)

class AIMusicGenerator:
    def __init__(self, device: str = None, use_cache: bool = True):
        """
        AI Music Generator d√πng MusicGen v·ªõi t·ªëi ∆∞u
        :param device: 'cpu', 'cuda', ho·∫∑c None (auto-detect)
        :param use_cache: B·∫≠t cache cho audio ƒë√£ generate
        """
        # Auto-detect device t·ªëi ∆∞u nh·∫•t
        if device is None:
            device = self._detect_best_device()
        
        self.device = device
        self.use_cache = use_cache
        self.cache_dir = "audio_cache"
        self.use_fp16 = (device == "cuda")  # Ch·ªâ d√πng FP16 khi c√≥ GPU
        
        if self.use_cache:
            os.makedirs(self.cache_dir, exist_ok=True)
        
        try:
            logger.info(f"üîÑ Loading MusicGen on {device}...")
            self.processor = AutoProcessor.from_pretrained("facebook/musicgen-small")
            self.model = MusicgenForConditionalGeneration.from_pretrained(
                "facebook/musicgen-small"
            ).to(device)
            
            # T·ªëi ∆∞u cho inference
            self.model.eval()
            
            # Ch·ªâ d√πng FP16 khi c√≥ GPU v√† ƒë·ªß VRAM
            if self.use_fp16:
                try:
                    self.model = self.model.half()
                    logger.info("‚úÖ Enabled FP16 for faster inference")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Cannot use FP16: {str(e)}, using FP32")
                    self.use_fp16 = False
            
            logger.info(f"‚úÖ Loaded MusicGen successfully on {device}")
        except Exception as e:
            logger.error(f"‚ùå Failed to load MusicGen: {str(e)}")
            raise
    
    def _detect_best_device(self) -> str:
        """
        T·ª± ƒë·ªông ph√°t hi·ªán v√† ch·ªçn device t·ªët nh·∫•t
        """
        # Ki·ªÉm tra CUDA (NVIDIA GPU)
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)  # GB
            logger.info(f"üéÆ GPU detected: {gpu_name} ({gpu_memory:.1f} GB VRAM)")
            
            # Ki·ªÉm tra xem c√≥ ƒë·ªß VRAM kh√¥ng (c·∫ßn √≠t nh·∫•t 2GB cho musicgen-small)
            if gpu_memory >= 2.0:
                logger.info("‚úÖ Using CUDA (GPU) - Expected 8-10x faster!")
                return "cuda"
            else:
                logger.warning(f"‚ö†Ô∏è GPU VRAM too low ({gpu_memory:.1f} GB), falling back to CPU")
                return "cpu"
        
        # Ki·ªÉm tra MPS (Apple Silicon M1/M2/M3)
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            logger.info("üçé Apple Silicon (MPS) detected - Expected 3-5x faster!")
            return "mps"
        
        # Fallback v·ªÅ CPU
        else:
            logger.info("üíª Using CPU - Generation will be slower (~60s for 10s audio)")
            return "cpu"
    
    def get_device_info(self) -> dict:
        """
        Tr·∫£ v·ªÅ th√¥ng tin v·ªÅ device ƒëang s·ª≠ d·ª•ng
        """
        info = {
            "device": self.device,
            "use_fp16": self.use_fp16,
            "cache_enabled": self.use_cache
        }
        
        if self.device == "cuda":
            info["gpu_name"] = torch.cuda.get_device_name(0)
            info["gpu_memory_gb"] = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            info["gpu_memory_allocated_gb"] = torch.cuda.memory_allocated(0) / (1024**3)
        
        return info

    def _build_prompt(self, instrument: str, style: str) -> str:
        instrument_map = {
            "sao_truc": "Vietnamese bamboo transverse flute S√°o Tr√∫c, airy, soft timbre, capable of bending notes",
            "sao_tieu": "Vietnamese vertical bamboo flute S√°o Ti√™u, mellow meditative low tone",
            "ken_bau": "Vietnamese conical oboe K√®n B·∫ßu, reedy, buzzing and powerful sound",
            "dan_tranh": "Vietnamese 16-string zither ƒê√†n Tranh, bright, metallic cascading tones with glissando",
            "dan_bau": "Vietnamese monochord ƒê√†n B·∫ßu, expressive bending pitch, soulful vocal-like timbre",
            "dan_nguyet": "Vietnamese moon lute ƒê√†n Nguy·ªát, clear metallic tone, traditional opera instrument",
            "dan_tinh": "Vietnamese lute ƒê√†n T√≠nh, gentle storytelling tone used in spiritual folk songs",
            "dan_ty_ba": "Vietnamese pear-shaped lute ƒê√†n T·ª≥ B√†, delicate articulate plucking tone",
            "dan_nhi": "Vietnamese two-string fiddle ƒê√†n Nh·ªã, nasal, emotional, expressive",
            "dan_gao": "Vietnamese coconut-shell fiddle ƒê√†n G√°o, rustic, folk tone",
            "dan_co": "Vietnamese spike fiddle ƒê√†n C√≤, high-pitched crying timbre",
            "trong_com": "Vietnamese barrel drum Tr·ªëng C∆°m, resonant deep bass sound",
            "phach": "Vietnamese wooden clappers Ph√°ch, dry sharp percussive click",
            "song_lang": "Vietnamese bamboo clapper Song Lang, sharp timing click",
            "chieng": "Vietnamese gong Chi√™ng, metallic reverberant tone",
            "t_rung": "Vietnamese bamboo xylophone T'r∆∞ng, bright cascading mountain echo tones",
            "k_longput": "Vietnamese bamboo percussion K'longput, resonant airy tones from clapped air",
            "dan_kni": "Vietnamese mouth fiddle ƒê√†n K'ni, haunting vocal-like resonance",
        }

        desc = instrument_map.get(instrument.lower(), f"Vietnamese folk instrument {instrument}")

        return (
            f"A high-quality {style} solo performance played only with the {desc}. "
            f"Expressive and natural playing, clean audio recording, "
            f"authentic Vietnamese sound. "
            f"No accompaniment, no background, no drums, no percussion, "
            f"no other instruments."
        )

    def _get_cache_key(self, instrument: str, style: str, duration: float) -> str:
        """T·∫°o unique key cho cache"""
        key_string = f"{instrument}_{style}_{duration}"
        return hashlib.md5(key_string.encode()).hexdigest()

    def _load_from_cache(self, cache_key: str) -> BytesIO:
        """Load audio t·ª´ cache n·∫øu c√≥"""
        cache_path = os.path.join(self.cache_dir, f"{cache_key}.wav")
        if os.path.exists(cache_path):
            with open(cache_path, 'rb') as f:
                audio_io = BytesIO(f.read())
                audio_io.seek(0)
                logger.info(f"üíæ Loaded from cache: {cache_key}")
                return audio_io
        return None

    def _save_to_cache(self, cache_key: str, audio_io: BytesIO):
        """L∆∞u audio v√†o cache"""
        cache_path = os.path.join(self.cache_dir, f"{cache_key}.wav")
        with open(cache_path, 'wb') as f:
            f.write(audio_io.getvalue())
        logger.info(f"üíæ Saved to cache: {cache_key}")

    def generate(self, instrument: str, style: str, duration: float) -> BytesIO:
        # Ki·ªÉm tra cache tr∆∞·ªõc
        if self.use_cache:
            cache_key = self._get_cache_key(instrument, style, duration)
            cached_audio = self._load_from_cache(cache_key)
            if cached_audio:
                return cached_audio

        prompt = self._build_prompt(instrument, style)
        
        try:
            # Preprocessing
            inputs = self.processor(
                text=[prompt],
                padding=True,
                return_tensors="pt"
            ).to(self.device)
            
            # Convert to FP16 n·∫øu d√πng GPU
            if self.device == "cuda":
                inputs = {k: v.half() if v.dtype == torch.float32 else v 
                         for k, v in inputs.items()}

            # T·ªëi ∆∞u s·ªë tokens: 40 tokens/gi√¢y thay v√¨ 50
            max_new_tokens = int(duration * 40)
            
            # Generate v·ªõi torch.no_grad() ƒë·ªÉ ti·∫øt ki·ªám memory
            with torch.no_grad():
                audio_values = self.model.generate(
                    **inputs,
                    max_new_tokens=max_new_tokens,
                    do_sample=True,  # Th√™m ƒë·ªÉ √¢m thanh ƒëa d·∫°ng h∆°n
                    temperature=1.0,  # C√≥ th·ªÉ ƒëi·ªÅu ch·ªânh
                    top_k=250,  # Gi·∫£m t·ª´ default ƒë·ªÉ nhanh h∆°n
                )

            sampling_rate = self.model.config.audio_encoder.sampling_rate
            audio_np = audio_values[0].cpu().numpy()

            # Normalize v√† convert sang int16
            audio_np = np.nan_to_num(audio_np)
            audio_np = (audio_np * 32767).astype(np.int16)

            audio_segment = AudioSegment(
                audio_np.tobytes(),
                frame_rate=sampling_rate,
                sample_width=2,
                channels=1
            )
            
            audio_io = BytesIO()
            audio_segment.export(audio_io, format="wav")
            audio_io.seek(0)
            
            # L∆∞u v√†o cache
            if self.use_cache:
                self._save_to_cache(cache_key, audio_io)
                audio_io.seek(0)  # Reset l·∫°i ƒë·ªÉ ƒë·ªçc
            
            return audio_io
            
        except Exception as e:
            logger.error(f"‚ùå Error generating audio for {instrument}: {str(e)}")
            raise

    def clear_cache(self):
        """X√≥a to√†n b·ªô cache"""
        if os.path.exists(self.cache_dir):
            import shutil
            shutil.rmtree(self.cache_dir)
            os.makedirs(self.cache_dir)
            logger.info("üóëÔ∏è Cache cleared")